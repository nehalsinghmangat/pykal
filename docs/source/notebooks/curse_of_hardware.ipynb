{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": "# The Curse of Hardware\n\n**← [Back to What is PyKal?](../what_is_pykal/index.rst)** | **[Previous: PyKal Workflow](pykal_workflow.ipynb)**\n\n---\n\nIn the pristine realm of theory, our sensors measure exactly what we want, our actuators execute precisely what we command, and our communication channels transmit data with perfect fidelity. Reality, however, has other plans.\n\nHardware is cursed. Sensors drift like unfaithful companions. Switches bounce like caffeinated rabbits. Wireless packets vanish into the electromagnetic void. And just when you think you've calibrated that IMU, thermal expansion whispers *\"think again.\"*\n\nThis notebook catalogues the menagerie of hardware maladies you **will** encounter in robotics, and—more importantly—the ``pykal.data`` utilities that can save you from debugging hell at 3 AM. We'll examine each corruption type, watch it destroy a perfectly good signal, then bring in the preparation methods to restore order.\n\nEach section follows the same structure:\n1. **The Corruption**: What breaks and why\n2. **The Demonstration**: Watching a clean signal get destroyed\n3. **The Salvation**: Applying the right preparation method\n4. **The Recovery**: Comparing corrupted vs cleaned signals\n\nLet us begin our descent into hardware chaos."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pykal.data_change import corrupt, prepare\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for nice plots\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Imports successful. Let the corruption begin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper",
   "metadata": {},
   "source": [
    "## Helper Function\n",
    "\n",
    "We'll use this to generate clean test signals throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clean_signal(n=200, signal_type='composite'):\n",
    "    \"\"\"Generate various clean test signals.\"\"\"\n",
    "    t = np.linspace(0, 4*np.pi, n)\n",
    "    \n",
    "    if signal_type == 'composite':\n",
    "        # Smooth signal with multiple frequency components\n",
    "        return t, np.sin(t) + 0.3*np.sin(3*t) + 0.5*np.cos(0.5*t)\n",
    "    elif signal_type == 'step':\n",
    "        # Step signal for testing bounce\n",
    "        signal = np.zeros(n)\n",
    "        signal[n//4:n//2] = 1.0\n",
    "        signal[3*n//4:] = 1.0\n",
    "        return t, signal\n",
    "    elif signal_type == 'ramp':\n",
    "        # Linear ramp for testing drift\n",
    "        return t, 0.5 * t\n",
    "    else:\n",
    "        return t, np.sin(t)\n",
    "\n",
    "print(\"✓ Helper function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gaussian_theory",
   "metadata": {},
   "source": [
    "## 1. Gaussian Noise: The Universal Tormentor\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Thermal noise. Quantization error. Electromagnetic interference. Johnson noise. Shot noise. The universe *really* wants your measurements to be wrong, and Gaussian noise is its favorite weapon.\n",
    "\n",
    "Every analog sensor suffers from it. Your accelerometer. Your force sensor. That temperature reading that keeps flickering by ±0.2°C. All victims of the same thermal demons.\n",
    "\n",
    "Mathematically, we model this as additive white Gaussian noise (AWGN):\n",
    "\n",
    "$$\n",
    "y_k = x_k + \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "where $x_k$ is your true signal and $\\mathcal{N}(0, \\sigma^2)$ is the noise with zero mean and variance $\\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gaussian_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "\n",
    "# Add Gaussian noise\n",
    "noisy = corrupt.with_gaussian_noise(clean, std=0.3, seed=42)\n",
    "\n",
    "# Plot: Clean vs Corrupted\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Signal (The Dream)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, noisy, 'r-', alpha=0.7, linewidth=1, label='Noisy Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('With Gaussian Noise (The Reality)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Signal-to-Noise Ratio: {10*np.log10(np.var(clean)/np.var(noisy - clean)):.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gaussian_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Low-Pass Filtering\n",
    "\n",
    "Gaussian noise is high-frequency chaos. Our signal? Usually smooth and low-frequency. The solution: **low-pass filters**.\n",
    "\n",
    "We have three weapons:\n",
    "1. **Moving Average**: Simple, intuitive, effective. Replaces each point with the average of its neighbors.\n",
    "2. **Exponential Smoothing**: Gives more weight to recent data. Good for real-time systems.\n",
    "3. **Low-Pass Filter**: Classic first-order filter. Think RC circuit in discrete time.\n",
    "\n",
    "Let's deploy all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gaussian_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different denoising methods\n",
    "cleaned_ma = prepare.with_moving_average(noisy, window=5)\n",
    "cleaned_exp = prepare.with_exponential_smoothing(noisy, alpha=0.2)\n",
    "cleaned_lp = prepare.with_low_pass_filter(noisy, alpha=0.2)\n",
    "\n",
    "# Plot: Corrupted vs Multiple Cleaning Methods\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, noisy, 'r-', alpha=0.5, linewidth=1, label='Noisy')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Corrupted Signal', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, clean, 'g-', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax2.plot(t, cleaned_ma, 'b-', linewidth=1.5, alpha=0.8, label='Moving Average')\n",
    "ax2.plot(t, cleaned_exp, 'm-', linewidth=1.5, alpha=0.6, label='Exponential Smoothing')\n",
    "ax2.plot(t, cleaned_lp, 'c-', linewidth=1.5, alpha=0.6, label='Low-Pass Filter')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Denoising (Victory!)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute recovery metrics\n",
    "mse_noisy = np.mean((noisy - clean)**2)\n",
    "mse_ma = np.mean((cleaned_ma - clean)**2)\n",
    "print(f\"MSE - Noisy: {mse_noisy:.4f}\")\n",
    "print(f\"MSE - Moving Average: {mse_ma:.4f}\")\n",
    "print(f\"Improvement: {((mse_noisy - mse_ma)/mse_noisy * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bounce_theory",
   "metadata": {},
   "source": [
    "## 2. Contact Bounce: The Fidgety Switch\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Press a button. It should go from 0 to 1. Clean. Simple. \n",
    "\n",
    "Instead, you get: 0→0.2→-0.1→0.8→1.2→0.9→1. \n",
    "\n",
    "Why? Because mechanical contacts don't close cleanly. They *bounce*. The metal surfaces make and break contact multiple times before settling. What should be a single transition becomes a flurry of oscillations.\n",
    "\n",
    "This plagues:\n",
    "- Limit switches on your robot arm\n",
    "- Encoder transitions on your wheels  \n",
    "- Any mechanical button or switch\n",
    "- Hall effect sensors detecting magnets\n",
    "\n",
    "The hardware folks solve this with capacitors. We solve it with math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bounce_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate step signal\n",
    "t, clean = generate_clean_signal(n=200, signal_type='step')\n",
    "\n",
    "# Add bounce\n",
    "bounced = corrupt.with_bounce(clean, duration=5, amplitude=0.3, seed=42)\n",
    "\n",
    "# Plot: Clean vs Bounced\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Signal Level')\n",
    "ax1.set_title('Clean Digital Signal (Ideal)', fontweight='bold')\n",
    "ax1.set_ylim([-0.5, 1.5])\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, bounced, 'r-', linewidth=1.5, label='Bounced Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Signal Level')\n",
    "ax2.set_title('With Contact Bounce (Mechanical Reality)', fontweight='bold')\n",
    "ax2.set_ylim([-0.5, 1.5])\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bounce_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Debouncing\n",
    "\n",
    "The fix: **require stability**. Don't accept a transition until the signal has stayed at the new level for several consecutive samples. This is the digital equivalent of \"are you *sure* you meant that?\"\n",
    "\n",
    "The ``debounce`` method implements this logic, filtering out the rapid oscillations while preserving genuine state changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bounce_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply debouncing\n",
    "debounced = prepare.with_debounce(bounced, threshold=0.1, min_duration=3)\n",
    "\n",
    "# Plot: Bounced vs Debounced\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, bounced, 'r-', linewidth=1.5, label='Bounced Signal')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Signal Level')\n",
    "ax1.set_title('With Bounce (The Problem)', fontweight='bold')\n",
    "ax1.set_ylim([-0.5, 1.5])\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, debounced, 'b-', linewidth=2, label='Debounced Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.5, linewidth=2, label='Original Clean')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Signal Level')\n",
    "ax2.set_title('After Debouncing (The Solution)', fontweight='bold')\n",
    "ax2.set_ylim([-0.5, 1.5])\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Recovery accuracy: {np.mean(np.abs(debounced - clean) < 0.1) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dropout_theory",
   "metadata": {},
   "source": [
    "## 3. Dropouts: The Vanishing Act\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Wireless communication is a beautiful lie. Your sensor sends data at 100 Hz. Your computer receives... 94 Hz? 87 Hz? Who knows! \n",
    "\n",
    "Packets disappear. Serial connections hiccup. I²C slaves get confused. Your sensor reading becomes:\n",
    "\n",
    "```\n",
    "[1.2, 1.3, NaN, NaN, 1.6, 1.7, NaN, 1.9]\n",
    "```\n",
    "\n",
    "Those NaNs? They're data points that never arrived. Your Kalman filter **hates** this.\n",
    "\n",
    "Common causes:\n",
    "- WiFi interference (looking at you, microwave)\n",
    "- Bluetooth packet collisions\n",
    "- Serial buffer overflow\n",
    "- Intermittent connections (loose wires, poor solder joints)\n",
    "- Sensor power glitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dropout_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "\n",
    "# Add dropouts\n",
    "dropout_data = corrupt.with_dropouts(clean, dropout_rate=0.15, seed=42)\n",
    "\n",
    "# Plot: Clean vs Dropout\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Signal (Perfect Communication)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot dropout data with gaps\n",
    "valid_mask = ~np.isnan(dropout_data)\n",
    "ax2.plot(t[valid_mask], dropout_data[valid_mask], 'r.', markersize=4, label='Received Data')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title(f'With Dropouts ({np.isnan(dropout_data).sum()} missing points)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Packet loss rate: {np.isnan(dropout_data).sum() / len(dropout_data) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dropout_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Interpolation\n",
    "\n",
    "Missing data? **Infer it** from neighboring points. Linear interpolation draws straight lines between known values. It's not perfect (the universe doesn't owe us linearity), but it's far better than NaN.\n",
    "\n",
    "For slowly-varying signals, this works remarkably well. Your position sensor dropped a reading? Interpolate from the last and next valid measurements. Much better than telling your controller \"the robot's position is undefined.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dropout_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply interpolation\n",
    "interpolated = prepare.with_interpolation(dropout_data, method='linear')\n",
    "\n",
    "# Plot: Dropout vs Interpolated\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "valid_mask = ~np.isnan(dropout_data)\n",
    "ax1.plot(t[valid_mask], dropout_data[valid_mask], 'r.', markersize=4, label='Received Data')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('With Dropouts (The Problem)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, interpolated, 'b-', linewidth=1.5, label='Interpolated Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.5, linewidth=2, label='Original Clean')\n",
    "ax2.plot(t[~valid_mask], interpolated[~valid_mask], 'rx', markersize=6, label='Interpolated Points')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Interpolation (The Solution)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = np.mean((interpolated - clean)**2)\n",
    "print(f\"Reconstruction MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "staleness_theory",
   "metadata": {},
   "source": [
    "## 3.5. Staleness Policies: The Update Rate Mismatch\n\n",
    "### The Problem\n\n",
    "Different sensors update at different rates. Your IMU: 200 Hz. Your GPS: 10 Hz. Your camera: 30 Hz.\n\n",
    "What happens when your control loop runs at 100 Hz but GPS hasn't sent new data in the last 5 iterations? Is that data still valid? Should you use it? Replace it with zeros? Hold the old value?\n\n",
    "This is the **staleness problem**. Data isn't wrong—it's just *old*. And different applications require different policies for handling old data.\n\n",
    "In `ROSNode` (see `src/pykal/ros_node.py`), we configure staleness policies per sensor:\n\n",
    "```python\n",
    "staleness_config = {\n",
    "    \"gps_position\": {\"after\": 0.5, \"policy\": \"hold\"},  # Hold for 0.5s\n",
    "    \"imu_accel\": {\"after\": 0.1, \"policy\": \"zero\"},     # Zero after 0.1s\n",
    "    \"camera_detection\": {\"after\": 1.0, \"policy\": \"drop\"}  # Drop after 1s\n",
    "}\n",
    "```\n\n",
    "The `pykal.data` module provides the same policies for offline testing and simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "staleness_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signal with dropouts (simulating stale data)\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "stale_data = corrupt.with_dropouts(clean, dropout_rate=0.20, seed=42)\n",
    "\n",
    "print(f\"Data with {np.isnan(stale_data).sum()} stale/missing points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "staleness_policies",
   "metadata": {},
   "source": [
    "### The Four Policies\n\n",
    "Let's see how each policy handles the same stale data:\n\n",
    "1. **'hold'**: Forward fill - hold last valid value (good for slowly-varying signals like GPS)\n",
    "2. **'zero'**: Replace with zeros (good for velocities, accelerations that should default to zero)\n",
    "3. **'drop'**: Remove stale points entirely (good for statistical processing)\n",
    "4. **'none'**: Keep NaN as-is (for debugging, or explicit handling downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "staleness_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different staleness policies\n",
    "policy_hold = prepare.with_staleness_policy(stale_data, policy='hold')\n",
    "policy_zero = prepare.with_staleness_policy(stale_data, policy='zero')\n",
    "policy_drop = prepare.with_staleness_policy(stale_data, policy='drop')\n",
    "policy_none = prepare.with_staleness_policy(stale_data, policy='none')\n\n",
    "# Plot: All four policies side by side\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n",
    "# Policy 1: Hold\n",
    "axes[0, 0].plot(t, policy_hold, 'b-', linewidth=2, label='Hold Policy')\n",
    "axes[0, 0].plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].set_ylabel('Amplitude')\n",
    "axes[0, 0].set_title('HOLD: Forward Fill (Last Valid Value)', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n\n",
    "# Policy 2: Zero\n",
    "axes[0, 1].plot(t, policy_zero, 'r-', linewidth=2, label='Zero Policy')\n",
    "axes[0, 1].plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "axes[0, 1].set_xlabel('Time')\n",
    "axes[0, 1].set_ylabel('Amplitude')\n",
    "axes[0, 1].set_title('ZERO: Replace with Zeros', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n\n",
    "# Policy 3: Drop\n",
    "t_drop = t[~np.isnan(stale_data)]  # Time points for valid data only\n",
    "axes[1, 0].plot(t_drop, policy_drop, 'mo', markersize=4, label='Drop Policy')\n",
    "axes[1, 0].plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Amplitude')\n",
    "axes[1, 0].set_title(f'DROP: Remove Stale Points ({len(policy_drop)} valid points)', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n\n",
    "# Policy 4: None\n",
    "valid_mask = ~np.isnan(policy_none)\n",
    "axes[1, 1].plot(t[valid_mask], policy_none[valid_mask], 'c.', markersize=4, label='Valid Data')\n",
    "axes[1, 1].plot(t[~valid_mask], [0]*np.sum(~valid_mask), 'rx', markersize=8, label='NaN (stale)')\n",
    "axes[1, 1].plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "axes[1, 1].set_xlabel('Time')\n",
    "axes[1, 1].set_ylabel('Amplitude')\n",
    "axes[1, 1].set_title('NONE: Keep NaN As-Is (No Processing)', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n\n",
    "plt.tight_layout()\n",
    "plt.show()\n\n",
    "print(\"\\nPolicy Comparison:\")\n",
    "print(f\"  Hold:  All {len(policy_hold)} points filled (forward fill)\")\n",
    "print(f\"  Zero:  All {len(policy_zero)} points filled (with zeros)\")\n",
    "print(f\"  Drop:  Only {len(policy_drop)} valid points kept\")\n",
    "print(f\"  None:  All {len(policy_none)} points kept ({np.isnan(policy_none).sum()} as NaN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "staleness_comparison",
   "metadata": {},
   "source": [
    "### When to Use Each Policy\n\n",
    "**HOLD (Forward Fill)**\n",
    "- Slowly-varying measurements (GPS position, temperature)\n",
    "- When continuity matters more than accuracy\n",
    "- State estimates that shouldn't suddenly jump to zero\n\n",
    "**ZERO**\n",
    "- Velocities, accelerations (physical quantities that default to zero at rest)\n",
    "- Control inputs (if no command, assume zero)\n",
    "- When a missing measurement means \"nothing is happening\"\n\n",
    "**DROP**\n",
    "- Statistical processing (mean, variance) where stale data skews results\n",
    "- When you have enough valid data and stale points would mislead\n",
    "- Sensor fusion where staleness is handled by the fusion algorithm\n\n",
    "**NONE**\n",
    "- Debugging (see exactly where data is missing)\n",
    "- When downstream code has explicit NaN handling\n",
    "- Passing to algorithms that require awareness of missing data\n\n",
    "### Real-World Example: Sensor Fusion\n\n",
    "In a typical robot, you might use:\n",
    "\n",
    "```python\n",
    "# Fast IMU: hold for 50ms, then zero (assume stopped if no updates)\n",
    "imu_data = prepare.with_staleness_policy(raw_imu, policy='zero')\n\n",
    "# Slow GPS: hold for 1 second (position doesn't change instantly)\n",
    "gps_data = prepare.with_staleness_policy(raw_gps, policy='hold')\n\n",
    "# Intermittent camera detections: drop if stale (don't use old detections)\n",
    "# This returns a shorter array, so handle separately\n",
    "valid_detections = prepare.with_staleness_policy(raw_detections, policy='drop')\n",
    "```\n\n",
    "This matches exactly how `ROSNode` handles staleness in real-time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bias_theory",
   "metadata": {},
   "source": [
    "## 4. Bias: The Systematic Liar\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Your accelerometer reads 0.3 m/s² when the robot is sitting still. Your force sensor outputs 12 N with no load. Your gyroscope thinks the world is rotating at 0.02 rad/s while the robot sleeps peacefully on your desk.\n",
    "\n",
    "This is **bias**: a constant offset in your measurements. Unlike noise (which averages to zero), bias is systematic. Every reading is wrong by the same amount.\n",
    "\n",
    "Causes:\n",
    "- Factory calibration drift\n",
    "- Temperature changes\n",
    "- Component aging\n",
    "- Poor zero-offset calibration\n",
    "- Magnetic interference (for magnetometers)\n",
    "\n",
    "The insidious part? Your sensor looks precise (low noise), but it's *inaccurate*. All those beautiful low-noise readings are consistently wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bias_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "\n",
    "# Add bias\n",
    "biased = corrupt.with_bias(clean, bias=0.8)\n",
    "\n",
    "# Plot: Clean vs Biased\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal')\n",
    "ax1.axhline(y=0, color='k', linestyle=':', alpha=0.5)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Signal (True Zero)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, biased, 'r-', linewidth=2, label='Biased Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "ax2.axhline(y=0.8, color='r', linestyle=':', alpha=0.5, label='Bias offset')\n",
    "ax2.axhline(y=0, color='k', linestyle=':', alpha=0.5)\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('With Constant Bias (Uncalibrated)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean error: {np.mean(biased - clean):.4f} (should equal bias)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bias_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Calibration\n",
    "\n",
    "The fix is almost offensively simple: **subtract the bias**. \n",
    "\n",
    "How do you find the bias? \n",
    "1. Put your sensor in a known state (robot stationary, no load on force sensor, etc.)\n",
    "2. Record many measurements\n",
    "3. Average them—that's your bias\n",
    "4. Subtract it from all future readings\n",
    "\n",
    "This is why good roboticists start every session with a calibration routine. Don't trust factory calibration. Don't trust yesterday's calibration. Calibrate. Every. Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bias_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply calibration (remove the bias)\n",
    "calibrated = prepare.with_calibration(biased, offset=0.8, scale=1.0)\n",
    "\n",
    "# Plot: Biased vs Calibrated\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, biased, 'r-', linewidth=2, label='Biased Signal')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.axhline(y=0.8, color='r', linestyle=':', alpha=0.5, label='Bias offset')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Biased Signal (The Problem)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, calibrated, 'b-', linewidth=2, label='Calibrated Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.5, linewidth=2, label='Original Clean')\n",
    "ax2.axhline(y=0, color='k', linestyle=':', alpha=0.5)\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Calibration (Perfect Recovery)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual error: {np.mean(np.abs(calibrated - clean)):.6f} (should be ~0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drift_theory",
   "metadata": {},
   "source": [
    "## 5. Drift: The Wandering Bias\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Calibrated your sensor? Great. Come back in 30 minutes—it's wrong again.\n",
    "\n",
    "**Drift** is bias that changes over time. Your gyroscope's zero-rate output slowly climbs. Your pressure sensor wanders as it warms up. Your strain gauge drifts as the sun heats your robot's frame.\n",
    "\n",
    "Mathematically:\n",
    "$$\n",
    "y_k = x_k + b_k, \\quad b_k = b_0 + \\alpha \\cdot k\n",
    "$$\n",
    "\n",
    "where $b_k$ is the time-varying bias and $\\alpha$ is the drift rate.\n",
    "\n",
    "This is particularly evil for:\n",
    "- Gyroscopes (integrate drift → your robot thinks it rotated 47° while sitting still)\n",
    "- Thermal sensors during warm-up\n",
    "- Analog circuits experiencing temperature changes\n",
    "- Any MEMS device over long time scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "\n",
    "# Add drift\n",
    "drifted = corrupt.with_drift(clean, drift_rate=0.008, drift_type='linear')\n",
    "\n",
    "# Plot: Clean vs Drifted\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Signal (Stable)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, drifted, 'r-', linewidth=2, label='Drifted Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "# Show the drift component\n",
    "drift_component = drifted - clean\n",
    "ax2.plot(t, drift_component, 'orange', linestyle=':', linewidth=2, label='Drift component')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('With Linear Drift (Sensor Warming Up)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total drift: {drift_component[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drift_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Periodic Re-Calibration\n",
    "\n",
    "Drift is trickier than static bias because it *changes*. Solutions:\n",
    "\n",
    "1. **Periodic re-calibration**: Return to known state, measure new bias, update offset\n",
    "2. **Sensor fusion**: Use drift-free sensors (accelerometers) to correct drifting ones (gyros)\n",
    "3. **Thermal modeling**: If drift correlates with temperature, model and compensate\n",
    "\n",
    "For demonstration, we'll use calibration with a time-varying offset estimate (simulating periodic re-calibration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate drift using first and last segments (simulating periodic calibration)\n",
    "# In practice, you'd recalibrate at known intervals\n",
    "# Here we'll use a simple high-pass filter to remove the drift trend\n",
    "\n",
    "# Method: Remove low-frequency trend with high-pass filtering\n",
    "from scipy import signal as scipy_signal\n",
    "\n",
    "# Design a high-pass filter to remove drift\n",
    "b, a = scipy_signal.butter(3, 0.05, btype='high', analog=False)\n",
    "detrended = scipy_signal.filtfilt(b, a, drifted)\n",
    "\n",
    "# Alternative: Simple detrending (subtract linear fit)\n",
    "coeffs = np.polyfit(t, drifted, deg=1)\n",
    "trend = np.polyval(coeffs, t)\n",
    "detrended_simple = drifted - trend + np.mean(clean)\n",
    "\n",
    "# Plot: Drifted vs Detrended\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, drifted, 'r-', linewidth=2, label='Drifted Signal')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.plot(t, trend, 'orange', linestyle=':', linewidth=2, label='Estimated trend')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Drifted Signal (The Problem)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, detrended_simple, 'b-', linewidth=2, label='Detrended Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.5, linewidth=2, label='Original Clean')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Detrending (The Solution)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = np.mean((detrended_simple - clean)**2)\n",
    "print(f\"Reconstruction MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spike_theory",
   "metadata": {},
   "source": [
    "## 6. Spikes: The Random Saboteurs\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Your sensor is humming along nicely: 1.2, 1.3, 1.35, **947.2**, 1.4, 1.38...\n",
    "\n",
    "Wait, what?\n",
    "\n",
    "**Spikes** (also called impulse noise or salt-and-pepper noise) are random, massive outliers. Causes:\n",
    "- Electromagnetic interference from nearby motors\n",
    "- Electrostatic discharge (you shuffled across the carpet, now your ADC thinks the world exploded)\n",
    "- Transmission errors (bit flip: 0b00000010 → 0b10000010)\n",
    "- Power supply glitches\n",
    "- Cosmic rays (yes, really—ask the CERN folks)\n",
    "\n",
    "These aren't Gaussian. They're rare but *huge*. And they'll wreck your control system if you let them through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spike_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "\n",
    "# Add spikes\n",
    "spiked = corrupt.with_spikes(clean, spike_rate=0.05, spike_magnitude=8.0, seed=42)\n",
    "\n",
    "# Plot: Clean vs Spiked\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Signal (EMI-Free Paradise)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, spiked, 'r-', linewidth=1, alpha=0.7, label='Spiked Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "# Highlight spikes\n",
    "spike_mask = np.abs(spiked - clean) > 2\n",
    "ax2.plot(t[spike_mask], spiked[spike_mask], 'r*', markersize=10, label='Spikes')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title(f'With Spikes ({spike_mask.sum()} detected)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spike_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Median Filtering & Outlier Removal\n",
    "\n",
    "**Median filters** are spike-killing machines. Unlike mean filters (which get dragged toward outliers), median filters replace each point with the *median* of its neighbors.\n",
    "\n",
    "Spike of 947.2 surrounded by [1.3, 1.35, 1.4]? Median says: \"1.35, you're up.\"\n",
    "\n",
    "For even better results, use **outlier removal** based on statistical tests (z-score). If a point is >3 standard deviations from the mean, it's probably not real data—replace it with the median or interpolate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spike_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply spike removal methods\n",
    "cleaned_median = prepare.with_median_filter(spiked, window=5)\n",
    "cleaned_outlier = prepare.with_outlier_removal(spiked, threshold=2.5, method='replace')\n",
    "\n",
    "# Plot: Spiked vs Cleaned\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, spiked, 'r-', linewidth=1, alpha=0.7, label='Spiked Signal')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "spike_mask = np.abs(spiked - clean) > 2\n",
    "ax1.plot(t[spike_mask], spiked[spike_mask], 'r*', markersize=10, label='Spikes')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('With Spikes (The Problem)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, clean, 'g-', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax2.plot(t, cleaned_median, 'b-', linewidth=1.5, label='Median Filter')\n",
    "ax2.plot(t, cleaned_outlier, 'm-', linewidth=1.5, alpha=0.7, label='Outlier Removal')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Spike Removal (Clean Victory)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Median filter MSE: {np.mean((cleaned_median - clean)**2):.4f}\")\n",
    "print(f\"Outlier removal MSE: {np.mean((cleaned_outlier - clean)**2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantization_theory",
   "metadata": {},
   "source": [
    "## 7. Quantization: The Staircase Effect\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Analog signals live in continuous land. Digital systems? Not so much.\n",
    "\n",
    "Your 8-bit ADC can represent exactly **256 discrete levels**. If your signal is 1.234567? Too bad—nearest level is 1.235. This is **quantization**: rounding continuous values to the nearest representable level.\n",
    "\n",
    "Low-resolution ADCs make this visible as a staircase effect. Your smooth velocity curve becomes a series of flat steps.\n",
    "\n",
    "This affects:\n",
    "- Low-bit ADCs (8-bit, 10-bit)\n",
    "- Integer encoders on motors\n",
    "- Digital potentiometers\n",
    "- Any continuous→discrete conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantization_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "\n",
    "# Add quantization (simulate 6-bit ADC: 64 levels)\n",
    "quantized = corrupt.with_quantization(clean, levels=64)\n",
    "\n",
    "# Plot: Clean vs Quantized\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal (Analog)')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Analog Signal', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, quantized, 'r-', linewidth=1.5, label='Quantized Signal (6-bit ADC)')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After 6-bit Quantization (64 levels)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of unique levels: {len(np.unique(quantized))}\")\n",
    "print(f\"Quantization MSE: {np.mean((quantized - clean)**2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantization_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Smoothing (with caution)\n",
    "\n",
    "Quantization error looks like high-frequency noise. Low-pass filtering can smooth out the staircases—but be careful! You're also removing real high-frequency content.\n",
    "\n",
    "Better solution? **Use a higher-resolution ADC**. Seriously. 12-bit and 16-bit ADCs are cheap. Don't fight quantization noise when you can just eliminate it.\n",
    "\n",
    "But if you're stuck with low-res hardware, gentle smoothing can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantization_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply smoothing to reduce quantization artifacts\n",
    "smoothed = prepare.with_moving_average(quantized, window=5)\n",
    "\n",
    "# Plot: Quantized vs Smoothed\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, quantized, 'r-', linewidth=1.5, label='Quantized Signal')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Quantized Signal (The Problem)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, smoothed, 'b-', linewidth=2, label='Smoothed Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.5, linewidth=2, label='Original Clean')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Smoothing (Partial Recovery)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Quantized MSE: {np.mean((quantized - clean)**2):.4f}\")\n",
    "print(f\"Smoothed MSE: {np.mean((smoothed - clean)**2):.4f}\")\n",
    "print(f\"Improvement: {((np.mean((quantized - clean)**2) - np.mean((smoothed - clean)**2)) / np.mean((quantized - clean)**2) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clipping_theory",
   "metadata": {},
   "source": [
    "## 8. Clipping/Saturation: The Ceiling and Floor\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Every sensor has a **range**. Your force sensor: 0-100 N. Your ADC: 0-5 V. Your motor encoder: -π to +π rad.\n",
    "\n",
    "What happens when the real value exceeds this range? **Clipping**. The measurement saturates at the limit:\n",
    "\n",
    "```\n",
    "True force:     [50, 75, 110, 95, 80]  N\n",
    "Measured force: [50, 75, 100, 95, 80]  N  (clipped at 100)\n",
    "```\n",
    "\n",
    "You lose information. That peak? Could've been 110 N. Could've been 500 N. You'll never know—your sensor hit its ceiling and stayed there.\n",
    "\n",
    "This is particularly dangerous because **clipped data looks valid**. No NaN, no error flag. Just a suspiciously flat plateau where there should be a peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clipping_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal with peaks\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "clean = 1.5 * clean  # Amplify to ensure some values exceed limits\n",
    "\n",
    "# Add clipping\n",
    "clipped = corrupt.with_clipping(clean, lower=-1.5, upper=1.5)\n",
    "\n",
    "# Plot: Clean vs Clipped\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal')\n",
    "ax1.axhline(y=1.5, color='r', linestyle='--', alpha=0.5, label='Sensor limits')\n",
    "ax1.axhline(y=-1.5, color='r', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Signal (True Values)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, clipped, 'r-', linewidth=2, label='Clipped Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "ax2.axhline(y=1.5, color='r', linestyle='--', alpha=0.5, label='Sensor limits')\n",
    "ax2.axhline(y=-1.5, color='r', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('With Clipping (Information Lost)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "saturated_points = np.sum((clipped == 1.5) | (clipped == -1.5))\n",
    "print(f\"Saturated points: {saturated_points} / {len(clipped)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clipping_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Detection and Flagging\n",
    "\n",
    "You **cannot** recover clipped data. The information is gone. But you *can* detect it and handle it gracefully:\n",
    "\n",
    "1. **Mark clipped values as invalid** (replace with NaN)\n",
    "2. **Flag them** so your controller knows \"this measurement is unreliable\"\n",
    "3. **Use sensor fusion** if you have redundant sensors with different ranges\n",
    "4. **Prevent it** by choosing sensors with appropriate ranges\n",
    "\n",
    "The ``clipping_recovery`` method detects saturation and optionally marks those points as invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clipping_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect and mark clipped values\n",
    "recovered = prepare.with_clipping_recovery(clipped, lower=-1.5, upper=1.5, mark_invalid=True)\n",
    "\n",
    "# Plot: Clipped vs Recovered\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clipped, 'r-', linewidth=2, label='Clipped Signal')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.axhline(y=1.5, color='r', linestyle='--', alpha=0.5, label='Sensor limits')\n",
    "ax1.axhline(y=-1.5, color='r', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clipped Signal (The Problem)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot valid points and marked invalid points separately\n",
    "valid_mask = ~np.isnan(recovered)\n",
    "ax2.plot(t[valid_mask], recovered[valid_mask], 'b-', linewidth=2, label='Valid Data')\n",
    "ax2.plot(t[~valid_mask], clipped[~valid_mask], 'rx', markersize=8, label='Detected Saturation (marked NaN)')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Detection (Invalid Points Marked)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detected {np.sum(~valid_mask)} saturated points\")\n",
    "print(\"Note: True values at these points are unknown (information permanently lost)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delay_theory",
   "metadata": {},
   "source": [
    "## 9. Delay/Latency: The Time Traveler\n",
    "\n",
    "### The Corruption\n",
    "\n",
    "Your sensor measures position at time $t_k$. Your computer receives that measurement at time $t_{k+3}$.\n",
    "\n",
    "**Latency** means your data is *correct* but **outdated**. You're making decisions based on old information—like driving while looking at a photo from 5 seconds ago.\n",
    "\n",
    "Sources:\n",
    "- Communication delays (WiFi, Bluetooth, serial)\n",
    "- Sensor processing time (camera exposure + processing)\n",
    "- Buffering in the OS or drivers\n",
    "- Network jitter\n",
    "\n",
    "This is particularly nasty for control systems. Your controller sends a command based on old state → system has already moved → command is wrong → instability.\n",
    "\n",
    "Mathematically:\n",
    "$$\n",
    "y_k = x_{k-d}\n",
    "$$\n",
    "where $d$ is the delay in samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delay_corrupt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean signal\n",
    "t, clean = generate_clean_signal(n=200)\n",
    "\n",
    "# Add delay\n",
    "delayed = corrupt.with_delay(clean, delay=10, fill_value=0.0)\n",
    "\n",
    "# Plot: Clean vs Delayed\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, clean, 'g-', linewidth=2, label='Clean Signal (Current)')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Clean Signal (Real-Time)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, delayed, 'r-', linewidth=2, label='Delayed Signal (10 samples)')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Clean (reference)')\n",
    "ax2.axvspan(t[0], t[10], alpha=0.2, color='gray', label='Delay period')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('With Delay (Time Shifted)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Phase shift: {10 / len(t) * 4 * np.pi:.2f} radians\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delay_prep",
   "metadata": {},
   "source": [
    "### The Salvation: Timestamping and Prediction\n",
    "\n",
    "You **cannot** remove latency after the fact. But you can mitigate it:\n",
    "\n",
    "1. **Timestamp everything**: Know *when* each measurement was taken\n",
    "2. **Predict forward**: Use a model to estimate current state from delayed measurement\n",
    "3. **Smith Predictor**: Classic control technique for dealing with known delays\n",
    "4. **Reduce latency**: Use faster communication, local processing, better hardware\n",
    "\n",
    "For demonstration, we'll show how timestamping reveals the delay, and how a simple forward prediction (assuming constant velocity) can compensate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delay_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple compensation: shift the delayed signal forward\n",
    "# In practice, you'd use a state estimator (Kalman filter) to predict forward\n",
    "compensated = np.roll(delayed, -10)\n",
    "compensated[-10:] = compensated[-11]  # Hold last value for the tail\n",
    "\n",
    "# Plot: Delayed vs Compensated\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(t, delayed, 'r-', linewidth=2, label='Delayed Signal')\n",
    "ax1.plot(t, clean, 'g--', alpha=0.3, linewidth=2, label='Original Clean')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_title('Delayed Signal (The Problem)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(t, compensated, 'b-', linewidth=2, label='Compensated Signal')\n",
    "ax2.plot(t, clean, 'g--', alpha=0.5, linewidth=2, label='Original Clean')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.set_title('After Delay Compensation (Time-Aligned)', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare alignment (ignoring the tail)\n",
    "mse_delayed = np.mean((delayed[:-10] - clean[:-10])**2)\n",
    "mse_compensated = np.mean((compensated[:-10] - clean[:-10])**2)\n",
    "print(f\"Delayed MSE: {mse_delayed:.4f}\")\n",
    "print(f\"Compensated MSE: {mse_compensated:.4f}\")\n",
    "print(f\"Improvement: {((mse_delayed - mse_compensated) / mse_delayed * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion: Survival Guide\n",
    "\n",
    "Hardware will betray you. It's not personal—it's physics, economics, and the second law of thermodynamics.\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "| Corruption | Cause | Solution |\n",
    "|------------|-------|----------|\n",
    "| **Gaussian Noise** | Thermal, quantization, EMI | Low-pass filtering, averaging |\n",
    "| **Bounce** | Mechanical contacts | Debouncing (require stability) |\n",
    "| **Dropouts** | Packet loss, intermittent connections | Interpolation, extrapolation |\n",
    "| **Staleness** | Different sensor update rates | Staleness policies (hold/zero/drop/none) |\n",
    "| **Bias** | Calibration drift, offsets | Calibration (subtract bias) |\n",
    "| **Drift** | Temperature, aging | Periodic re-calibration, detrending |\n",
    "| **Spikes** | EMI, glitches, cosmic rays | Median filtering, outlier removal |\n",
    "| **Quantization** | Low-resolution ADC | Smoothing (or buy better hardware) |\n",
    "| **Clipping** | Sensor saturation | Detection, flagging (information lost) |\n",
    "| **Delay** | Communication latency | Timestamping, prediction |\n",
    "\n",
    "### The PyKal Philosophy\n",
    "\n",
    "1. **Simulate before you build**: Use ``corrupt.*`` to test your estimators with realistic noise *before* buying hardware\n",
    "2. **Prepare defensively**: Apply ``prepare.*`` methods in your data pipeline *before* feeding measurements to controllers\n",
    "3. **Know your enemy**: Different corruptions need different solutions—median filters for spikes, calibration for bias\n",
    "4. **Trust, but verify**: Just because data looks clean doesn't mean it is. Add sanity checks.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Integrate these methods into your ``ROSNode`` callbacks (see ``ros_node.py``)\n",
    "- Use the same covariance matrix ``Q`` for both corruption (testing) and Kalman filtering (estimation)\n",
    "- Build a pre-processing pipeline: interpolation → outlier removal → calibration → low-pass filtering\n",
    "- Test your control system with increasingly severe corruption until it breaks, then fix it\n",
    "\n",
    "Remember: **Hardware is cursed, but we have the tools to break the curse.**\n",
    "\n",
    "Now go forth and build robots that work in reality, not just in simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"THE CURSE OF HARDWARE: SURVIVED\")\nprint(\"=\"*60)\nprint(\"\\nYou now have the knowledge to:\")\nprint(\"  ✓ Recognize hardware corruption patterns\")\nprint(\"  ✓ Apply appropriate preparation methods\")\nprint(\"  ✓ Build robust data pipelines\")\nprint(\"  ✓ Test estimators with realistic noise\")\nprint(\"\\nGo build something that works in the real world.\")\nprint(\"=\"*60)\n\n---\n\n## Navigation\n\n**[Previous: PyKal Workflow](pykal_workflow.ipynb)** | **Next: [Simulating the Curse →](simulating_the_curse.ipynb)**\n\n**← [Back to What is PyKal?](../what_is_pykal/index.rst)**"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}