{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LQR Control in pykal\n",
    "\n",
    "This notebook demonstrates the implementation of a Linear Quadratic Regulator (LQR) controller in pykal, based on Kalman's seminal work on optimal control theory [1].\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The LQR controller computes the optimal state feedback gain that minimizes a quadratic cost function for linear discrete-time systems. It is widely used in aerospace, robotics, and process control applications.\n",
    "\n",
    "**Problem formulation:**\n",
    "\n",
    "For a linear discrete-time system:\n",
    "\n",
    "$$x_{k+1} = A x_k + B u_k$$\n",
    "\n",
    "The LQR controller minimizes the infinite-horizon cost:\n",
    "\n",
    "$$J = \\sum_{k=0}^{\\infty} \\left( x_k^T Q x_k + u_k^T R u_k \\right)$$\n",
    "\n",
    "where:\n",
    "- $Q$ (n \u00d7 n) penalizes state deviations (positive semi-definite)\n",
    "- $R$ (m \u00d7 m) penalizes control effort (positive definite)\n",
    "\n",
    "**Optimal control law:**\n",
    "\n",
    "$$u_k = -K (x_k - x_{\\text{ref}})$$\n",
    "\n",
    "where $K$ is the optimal feedback gain computed by solving the Discrete-Time Algebraic Riccati Equation (DARE).\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Kalman, R. E. (1960). Contributions to the theory of optimal control. *Boletin de la Sociedad Matematica Mexicana*, 5(2), 102-119."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pykal import DynamicalSystem\n",
    "from pykal.algorithm_library.controllers.lqr import LQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Model: Double Integrator\n",
    "\n",
    "We'll control a double integrator system (e.g., a mass on a frictionless surface):\n",
    "\n",
    "$$\\ddot{x} = u$$\n",
    "\n",
    "where $x$ is position and $u$ is acceleration (control input).\n",
    "\n",
    "**State-space representation:**\n",
    "\n",
    "State: $\\mathbf{x} = [x, \\dot{x}]^T$ (position, velocity)\n",
    "\n",
    "**Continuous-time:**\n",
    "$$\\dot{\\mathbf{x}} = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix} \\mathbf{x} + \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} u$$\n",
    "\n",
    "**Discrete-time (Euler integration, dt=0.1):**\n",
    "$$\\mathbf{x}_{k+1} = \\begin{bmatrix} 1 & 0.1 \\\\ 0 & 1 \\end{bmatrix} \\mathbf{x}_k + \\begin{bmatrix} 0.005 \\\\ 0.1 \\end{bmatrix} u_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "dt = 0.1  # 100 ms time step\n",
    "T = 10.0  # 10 second simulation\n",
    "N = int(T / dt)\n",
    "time = np.arange(N) * dt\n",
    "\n",
    "# Discrete-time system matrices (Euler discretization)\n",
    "A = np.array([[1.0, dt],\n",
    "              [0.0, 1.0]])\n",
    "B = np.array([[0.5 * dt**2],\n",
    "              [dt]])\n",
    "\n",
    "print(f\"System matrices:\")\n",
    "print(f\"A = \\n{A}\")\n",
    "print(f\"B = \\n{B}\")\n",
    "\n",
    "# Check controllability\n",
    "C_matrix = np.hstack([B, A @ B])\n",
    "rank = np.linalg.matrix_rank(C_matrix)\n",
    "print(f\"\\nControllability matrix rank: {rank} (system dimension: {A.shape[0]})\")\n",
    "print(f\"System is {'controllable' if rank == A.shape[0] else 'NOT controllable'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LQR Gain Computation\n",
    "\n",
    "We'll design an LQR controller with the following tuning:\n",
    "\n",
    "- $Q = \\text{diag}(10, 1)$: Prioritize position error (10\u00d7) over velocity error\n",
    "- $R = 1$: Moderate control effort penalty\n",
    "\n",
    "This balance will give us fast position tracking with reasonable control inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LQR cost matrices\n",
    "Q = np.diag([10.0, 1.0])  # State cost: prioritize position\n",
    "R = np.array([[1.0]])      # Control cost\n",
    "\n",
    "# Compute optimal LQR gain\n",
    "K, P = LQR.compute_gain(A, B, Q, R)\n",
    "\n",
    "print(f\"Optimal feedback gain K:\")\n",
    "print(K)\n",
    "print(f\"\\nDARE solution P:\")\n",
    "print(P)\n",
    "\n",
    "# Analyze closed-loop stability\n",
    "A_cl = A - B @ K\n",
    "eigenvalues = np.linalg.eigvals(A_cl)\n",
    "print(f\"\\nClosed-loop eigenvalues: {eigenvalues}\")\n",
    "print(f\"Spectral radius: {np.max(np.abs(eigenvalues)):.4f}\")\n",
    "print(f\"System is {'stable' if np.all(np.abs(eigenvalues) < 1.0) else 'UNSTABLE'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DynamicalSystem Instances\n",
    "\n",
    "We'll create:\n",
    "1. **Plant**: The double integrator system\n",
    "2. **Controller**: The LQR controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant dynamics\n",
    "def plant_f(x, u):\n",
    "    \"\"\"Double integrator state evolution.\"\"\"\n",
    "    return A @ x + B.flatten() * u\n",
    "\n",
    "def plant_h(x):\n",
    "    \"\"\"Full state observation.\"\"\"\n",
    "    return x\n",
    "\n",
    "# Initial conditions\n",
    "x0 = np.array([5.0, 0.0])  # Start 5 units from origin, at rest\n",
    "lqr_state0 = (K, P)        # LQR controller state\n",
    "\n",
    "# Shared parameter dictionary\n",
    "params = {\n",
    "    'x': x0,\n",
    "    'lqr_state': lqr_state0,\n",
    "    'u': 0.0,\n",
    "    'xhat_k': x0,\n",
    "    'xref_k': np.array([0.0, 0.0])  # Regulate to origin\n",
    "}\n",
    "\n",
    "# Create plant system\n",
    "plant = DynamicalSystem(\n",
    "    f=plant_f,\n",
    "    h=plant_h,\n",
    "    state_name='x'\n",
    ")\n",
    "\n",
    "# Create LQR controller\n",
    "controller = DynamicalSystem(\n",
    "    f=LQR.f,\n",
    "    h=LQR.h,\n",
    "    state_name='lqr_state'\n",
    ")\n",
    "\n",
    "print(\"DynamicalSystem instances created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Closed-Loop Simulation\n",
    "\n",
    "We'll simulate the closed-loop system tracking a step reference that changes at t=5s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage arrays\n",
    "x_history = np.zeros((N, 2))\n",
    "u_history = np.zeros(N)\n",
    "r_history = np.zeros((N, 2))\n",
    "\n",
    "# Simulation loop\n",
    "for k in range(N):\n",
    "    # Update reference (step change at t=5s)\n",
    "    if time[k] < 5.0:\n",
    "        params['xref_k'] = np.array([0.0, 0.0])  # Origin\n",
    "    else:\n",
    "        params['xref_k'] = np.array([3.0, 0.0])  # Move to x=3\n",
    "    \n",
    "    # Get current state (measurement)\n",
    "    x_k = plant.step(param_dict=params)\n",
    "    params['xhat_k'] = x_k  # Perfect state feedback\n",
    "    \n",
    "    # Controller computes control input\n",
    "    u_k = controller.step(param_dict=params)\n",
    "    params['u'] = u_k[0] if isinstance(u_k, np.ndarray) else u_k\n",
    "    \n",
    "    # Store history\n",
    "    x_history[k] = x_k\n",
    "    u_history[k] = params['u']\n",
    "    r_history[k] = params['xref_k']\n",
    "\n",
    "print(\"Simulation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "Let's visualize the tracking performance, control effort, and phase portrait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 9))\n",
    "\n",
    "# Plot 1: Position tracking\n",
    "axes[0].plot(time, r_history[:, 0], 'r--', linewidth=2, label='Reference $x_{ref}(t)$')\n",
    "axes[0].plot(time, x_history[:, 0], 'b-', linewidth=1.5, label='Actual $x(t)$')\n",
    "axes[0].set_ylabel('Position', fontsize=12)\n",
    "axes[0].set_title('LQR Control Performance: Double Integrator', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Velocity\n",
    "axes[1].plot(time, r_history[:, 1], 'r--', linewidth=2, label='Reference $\\dot{x}_{ref}(t)$')\n",
    "axes[1].plot(time, x_history[:, 1], 'b-', linewidth=1.5, label='Actual $\\dot{x}(t)$')\n",
    "axes[1].set_ylabel('Velocity', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Control input\n",
    "axes[2].plot(time, u_history, 'g-', linewidth=1.5)\n",
    "axes[2].set_ylabel('Control Input $u(t)$', fontsize=12)\n",
    "axes[2].set_xlabel('Time (seconds)', fontsize=12)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase portrait\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "ax.plot(x_history[:, 0], x_history[:, 1], 'b-', linewidth=1.5, label='Trajectory')\n",
    "ax.plot(x_history[0, 0], x_history[0, 1], 'go', markersize=10, label='Start')\n",
    "ax.plot(x_history[-1, 0], x_history[-1, 1], 'rs', markersize=10, label='End')\n",
    "ax.plot(r_history[:, 0], r_history[:, 1], 'r*', markersize=12, label='References')\n",
    "\n",
    "ax.set_xlabel('Position $x$', fontsize=12)\n",
    "ax.set_ylabel('Velocity $\\dot{x}$', fontsize=12)\n",
    "ax.set_title('Phase Portrait', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance metrics\n",
    "position_error = x_history[:, 0] - r_history[:, 0]\n",
    "velocity_error = x_history[:, 1] - r_history[:, 1]\n",
    "\n",
    "# Settling time (2% criterion)\n",
    "settling_threshold = 0.02 * np.abs(x0[0])\n",
    "settled_indices = np.where(np.abs(position_error[:50]) < settling_threshold)[0]\n",
    "settling_time = time[settled_indices[-1]] if len(settled_indices) > 0 else None\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Final position error: {position_error[-1]:.6f}\")\n",
    "print(f\"Final velocity error: {velocity_error[-1]:.6f}\")\n",
    "print(f\"RMS position error: {np.sqrt(np.mean(position_error**2)):.6f}\")\n",
    "print(f\"Max control effort: {np.max(np.abs(u_history)):.3f}\")\n",
    "if settling_time:\n",
    "    print(f\"Settling time (2%): {settling_time:.2f} s\")\n",
    "\n",
    "# Verify cost reduction\n",
    "state_cost = np.sum([x.T @ Q @ x for x in x_history])\n",
    "control_cost = np.sum([u**2 * R[0,0] for u in u_history])\n",
    "total_cost = state_cost + control_cost\n",
    "print(f\"\\nTotal cost J: {total_cost:.2f}\")\n",
    "print(f\"  State cost:   {state_cost:.2f}\")\n",
    "print(f\"  Control cost: {control_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "\u2713 **LQR controller implementation** in pykal using the `DynamicalSystem` framework\n",
    "\n",
    "\u2713 **DARE solution** via `LQR.compute_gain()` for optimal feedback gain\n",
    "\n",
    "\u2713 **Closed-loop simulation** of a double integrator system\n",
    "\n",
    "\u2713 **Performance analysis** showing fast convergence and optimality\n",
    "\n",
    "The LQR controller successfully:\n",
    "- Stabilized the double integrator from initial condition $x_0 = [5, 0]$ to origin\n",
    "- Tracked a step reference change at $t = 5$ s\n",
    "- Minimized the quadratic cost function\n",
    "- Guaranteed closed-loop stability (eigenvalues inside unit circle)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Deploy on TurtleBot3**: See `lqr_turtlebot.ipynb` for trajectory tracking on a mobile robot\n",
    "- **Deploy on Crazyflie**: See `lqr_crazyflie.ipynb` for attitude control on a quadrotor\n",
    "- **Experiment with tuning**: Adjust $Q$ and $R$ to trade off performance vs. control effort\n",
    "- **Add disturbances**: Test robustness to external forces and measurement noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}