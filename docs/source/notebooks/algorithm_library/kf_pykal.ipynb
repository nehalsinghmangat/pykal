{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\u2190 Algorithms as Dynamical Systems](../../getting_started/theory_to_python/algorithms_as_dynamical_systems.rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165314ec",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    ":::note\n",
    "This notebook serves as a template for implementing state estimation algorithms as dynamical systems using pykal. Templating advice is boxed in blue.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b46a49",
   "metadata": {},
   "source": [
    "# Example: Kalman Filter\n",
    "\n",
    ":::note\n",
    "The title of the notebook should be the name of the algorithm. The text beneath the title should serve as a general overview of your algorithm, including links to useful materials. If your algorithm is included in the `pykal.algorithm_library`, then include a link to the API reference. We give an example below.\n",
    ":::\n",
    "\n",
    "The Kalman filter is a (linearly) optimal state estimation algorithm. The optimality is also conditional on the process and measurement noise being Gaussian. This algorithm works in two phases: a **prediction** phase and an **update** phase. For further information, read the [Wikipedia article](https://en.wikipedia.org/wiki/Kalman_filter). For Kalman's original paper on arxiv, which has a wonderful manifold projection interpretation of optimal estimation, read [the paper here ](https://www.cs.cmu.edu/~motionplanning/papers/sbp_papers/k/Kalman1960.pdf?utm_source=chatgpt.com).\n",
    "\n",
    "The Kalman filter dynamical system as implemented in this notebook may be found in `pykal.algorithm_library.kf`.\n",
    "\n",
    "The Kalman filter is an optimal state estimator for linear Gaussian systems. It recursively estimates the state of a dynamic system from noisy measurements by performing a predict-update cycle at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad5f15",
   "metadata": {},
   "source": [
    "## Definition of Algorithm\n",
    "\n",
    ":::note\n",
    "Define the algorithm here. Derivation is unnecessary, but can be referenced using links. The definition must be self-contained; that is, all assumptions must be stated and variables must be defined. We demonstrate by example below.\n",
    ":::\n",
    "\n",
    "We model a discrete-time linear dynamical system with Gaussian noise by\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{k+1} &= F_k x_k + B_k u_k + w_k, \\\\\n",
    "y_k     &= H_k x_k + v_k.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where\n",
    "- $x_k \\in \\mathbb{R}^n$ is the (hidden) state at time step $k$,\n",
    "- $u_k \\in \\mathbb{R}^p$ is a known control input,\n",
    "- $y_k \\in \\mathbb{R}^m$ is the measurement,\n",
    "- $F_k \\in \\mathbb{R}^{n\\times n}$ is the state transition matrix,\n",
    "- $B_k \\in \\mathbb{R}^{n\\times p}$ is the control-input matrix,\n",
    "- $H_k \\in \\mathbb{R}^{m\\times n}$ is the measurement matrix.\n",
    "\n",
    "The process noise and measurement noise are modeled as zero-mean Gaussian random variables\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w_k & \\sim \\mathcal{N}(0, Q_k)\\\\\n",
    "v_k & \\sim \\mathcal{N}(0, R_k)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "with covariances $Q_k \\in \\mathbb{R}^{n\\times n}$ and $R_k \\in \\mathbb{R}^{m\\times m}$. We also assume an initial Gaussian prior\n",
    "\n",
    "$$\n",
    "x_0 \\sim \\mathcal{N}(\\hat{x}_{0|0}, P_{0|0}).\n",
    "$$\n",
    "\n",
    "The Kalman filter produces, at each time $k$, a Gaussian posterior estimate of the state conditioned on measurements up to time $k$:\n",
    "\n",
    "$$\n",
    "p(x_k \\mid y_{0:k}) \\approx \\mathcal{N}(\\hat{x}_{k|k}, P_{k|k}),\n",
    "$$\n",
    "\n",
    "where $\\hat{x}_{k|k}$ is the posterior mean (state estimate) and $P_{k|k}$ is the posterior covariance (uncertainty).\n",
    "\n",
    "### Predict Step\n",
    "\n",
    "Given $(\\hat{x}_{k|k}, P_{k|k})$, the filter predicts the state at the next time step:\n",
    "\n",
    "$$\n",
    "\\hat{x}_{k+1|k} = F_k \\hat{x}_{k|k} + B_k u_k,\n",
    "$$\n",
    "$$\n",
    "P_{k+1|k} = F_k P_{k|k} F_k^\\top + Q_k.\n",
    "$$\n",
    "\n",
    "### Update Step\n",
    "\n",
    "When a new measurement $y_{k+1}$ is observed, form the innovation (residual)\n",
    "\n",
    "$$\n",
    "r_{k+1} = y_{k+1} - H_{k+1}\\hat{x}_{k+1|k},\n",
    "$$\n",
    "and its covariance\n",
    "\n",
    "$$\n",
    "S_{k+1} = H_{k+1} P_{k+1|k} H_{k+1}^\\top + R_{k+1}.\n",
    "$$\n",
    "\n",
    "The Kalman gain is\n",
    "\n",
    "$$\n",
    "K_{k+1} = P_{k+1|k} H_{k+1}^\\top S_{k+1}^{-1}.\n",
    "$$\n",
    "\n",
    "Then the posterior mean and covariance are updated by\n",
    "\n",
    "$$\n",
    "\\hat{x}_{k+1|k+1} = \\hat{x}_{k+1|k} + K_{k+1} r_{k+1},\n",
    "$$\n",
    "$$\n",
    "P_{k+1|k+1} = (I - K_{k+1}H_{k+1}) P_{k+1|k}.\n",
    "$$\n",
    "\n",
    "A numerically safer equivalent covariance update (the Joseph form) is\n",
    "\n",
    "$$\n",
    "P_{k+1|k+1} = (I - K_{k+1}H_{k+1})P_{k+1|k}(I - K_{k+1}H_{k+1})^\\top + K_{k+1} R_{k+1} K_{k+1}^\\top.\n",
    "$$\n",
    "\n",
    "### Optimality Statement\n",
    "\n",
    "Under the linear-Gaussian assumptions above, the Kalman filter computes the exact posterior mean and covariance, and $\\hat{x}_{k|k}$ is the minimum mean-square error (MMSE) estimator of $x_k$ given $y_{0:k}$. Equivalently, among all estimators that are affine functions of the measurements, it is the best linear unbiased estimator (BLUE) when the relevant moments exist.\n",
    "\n",
    "In practice, the Kalman filter is implemented as the recursive map\n",
    "\n",
    "$$\n",
    "(\\hat{x}_{k|k}, P_{k|k}) \\mapsto (\\hat{x}_{k+1|k+1}, P_{k+1|k+1}),\n",
    "$$\n",
    "\n",
    "driven by inputs $(u_k, y_{k+1})$ and parameters $(F_k, B_k, H_{k+1}, Q_k, R_{k+1})$.\n",
    "\n",
    "For a full derivation, see [Kalman's original paper](https://ntrs.nasa.gov/citations/19860016041) or [this tutorial](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1449379",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Algorithm as a Dynamical System\n",
    "::: note\n",
    "With reference to the definition of the algorithm as needed, define the dynamical system representation of the algorithm. As before, the definition must be self-contained; that is, all assumptions must be stated and variables must be defined. After the definition, show the evolution function (`f`) and output function (`h`) implementation in Python. We demonstrate by example below.\n",
    ":::\n",
    "To represent the Kalman Filter (KF) as a **discrete-time dynamical system**, we define the *algorithm state* to be the pair\n",
    "\n",
    "$$\n",
    "z_k := (\\hat{x}_{k|k}, P_{k|k}),\n",
    "$$\n",
    "\n",
    "where $\\hat{x}_{k|k} \\in \\mathbb{R}^n$ is the current state estimate (posterior mean) and $P_{k|k} \\in \\mathbb{R}^{n\\times n}$ is the current posterior covariance. The algorithm is driven by a measurement input\n",
    "\n",
    "$$\n",
    "u_k := y_k \\in \\mathbb{R}^m,\n",
    "$$\n",
    "\n",
    "and (optionally) by an external control input $u_k^{\\text{plant}}$ that is embedded inside the parameter dictionary passed to the model function.\n",
    "\n",
    "We assume that the plant model and measurement model are available as **noise-free** functions\n",
    "\n",
    "$$\n",
    "f:\\mathbb{R}^n \\to \\mathbb{R}^n, \\qquad h:\\mathbb{R}^n \\to \\mathbb{R}^m,\n",
    "$$\n",
    "\n",
    "together with matrices (or Jacobians) $F_k \\in \\mathbb{R}^{n\\times n}$ and $H_k \\in \\mathbb{R}^{m\\times n}$ used to propagate covariance and form the measurement update, and noise covariances $Q_k \\succeq 0$ and $R_k \\succ 0$.\n",
    "\n",
    "With this setup, the Kalman filter is exactly the recursion\n",
    "\n",
    "$$\n",
    "z_{k+1} = \\Phi(z_k, y_{k+1}; \\theta_k),\n",
    "$$\n",
    "\n",
    "where $\\theta_k$ denotes the collection of parameters required at time $k$ (e.g., the model functions, their parameters, and the matrices $F_k,H_k,Q_k,R_k$). Concretely, the state transition map $\\Phi$ is the standard predict\u2013update cycle:\n",
    "\n",
    "**Predict**\n",
    "\n",
    "$$\n",
    "\\hat{x}_{k+1|k} = f(\\hat{x}_{k|k}; \\theta_k),\n",
    "$$\n",
    "$$\n",
    "P_{k+1|k} = F_k P_{k|k} F_k^\\top + Q_k.\n",
    "$$\n",
    "\n",
    "**Update**\n",
    "\n",
    "$$\n",
    "\\hat{y}_{k+1|k} = h(\\hat{x}_{k+1|k}; \\theta_k),\n",
    "\\qquad\n",
    "r_{k+1} = y_{k+1} - \\hat{y}_{k+1|k},\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_{k+1} = H_k P_{k+1|k} H_k^\\top + R_k,\n",
    "\\qquad\n",
    "K_{k+1} = P_{k+1|k} H_k^\\top S_{k+1}^{-1},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{x}_{k+1|k+1} = \\hat{x}_{k+1|k} + K_{k+1} r_{k+1},\n",
    "$$\n",
    "\n",
    "and we update covariance using the Joseph form\n",
    "\n",
    "$$\n",
    "P_{k+1|k+1}\n",
    "=\n",
    "(I - K_{k+1}H_k)P_{k+1|k}(I - K_{k+1}H_k)^\\top\n",
    "+\n",
    "K_{k+1}R_kK_{k+1}^\\top,\n",
    "$$\n",
    "\n",
    "which is numerically stable and preserves positive semidefiniteness better in finite precision arithmetic.\n",
    "\n",
    "Finally, we define the algorithm output as the estimated state:\n",
    "\n",
    "$$\n",
    "\\psi(z_k) = \\hat{x}_{k|k}.\n",
    "$$\n",
    "\n",
    "In `pykal`, this corresponds exactly to:\n",
    "- **State transition**: `f(...)` implements $\\Phi$ (one full predict\u2013update step), taking $(\\hat{x}_{k|k}, P_{k|k})$ and the new measurement $y_k$ (plus parameters) and returning $(\\hat{x}_{k+1|k+1}, P_{k+1|k+1})$.\n",
    "- **Output map**: `h(xhat_P)` implements $\\psi$ by extracting $\\hat{x}$ from the tuple $(\\hat{x}, P)$.\n",
    "\n",
    "We implement $\\Phi$ as a callable with signature\n",
    "\n",
    "$$\n",
    "(\\hat{x}_{k|k}, P_{k|k}) \\mapsto (\\hat{x}_{k+1|k+1}, P_{k+1|k+1})\n",
    "$$\n",
    "\n",
    "driven by measurement input $y_k$, with:\n",
    "- `f(**f_params)` returning $\\hat{x}_{k+1|k}$,\n",
    "- `h(**h_params)` returning $\\hat{y}_{k|k-1}$,\n",
    "- `Fk, Hk` used for covariance propagation and update,\n",
    "- `Qk, Rk` encoding process and measurement noise covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea119635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In addition to importing the DynamicalSystem Module, import any other packages that are necessary here. For example, if your algorithm uses \"scipy\" or \"cvxpy\", import them below.\n",
    "\n",
    "\n",
    "import typing  # for function signatures\n",
    "from typing import Tuple, Callable, Dict\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "def f(\n",
    "    *,\n",
    "    xhat_P: Tuple[NDArray, NDArray],\n",
    "    yk: NDArray,\n",
    "    f: Callable,\n",
    "    f_params: Dict,\n",
    "    h: Callable,\n",
    "    h_params: Dict,\n",
    "    Fk: NDArray,\n",
    "    Qk: NDArray,\n",
    "    Hk: NDArray,\n",
    "    Rk: NDArray,\n",
    ") -> Tuple[NDArray, NDArray]:\n",
    "    \"\"\"\n",
    "    Perform one full **predict\u2013update** step of the discrete-time Kalman Filter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xhat_P : Tuple[NDArray, NDArray]\n",
    "        A tuple ``(x_hat_k, P_k)`` containing:\n",
    "            - ``x_hat_k`` : the current estimated state of the plant, shape (n,1)\n",
    "            - ``P_k``     : the current state covariance, shape (n,n)\n",
    "\n",
    "    yk : NDArray\n",
    "        The measurement at time k, shape (m,1).\n",
    "\n",
    "    f : Callable\n",
    "        The plant evolution function used to propagate the estimated mean:\n",
    "            ``x_pred = f(**f_params)``\n",
    "        This should return the **noise-free** predicted state.\n",
    "\n",
    "    f_params : Dict\n",
    "        Dictionary of parameters passed to the evolution function ``f``.\n",
    "\n",
    "    h : Callable\n",
    "        The plant output function used to compute the predicted measurement:\n",
    "            ``y_pred = h(**h_params)``\n",
    "        This should return the **noise-free** predicted measurement.\n",
    "\n",
    "    h_params : Dict\n",
    "        Dictionary of parameters passed to the measurement function ``h``.\n",
    "\n",
    "    Fk : NDArray\n",
    "        The state-transition Jacobian evaluated at the current estimate,\n",
    "        used to propagate the covariance. Shape (n,n).\n",
    "\n",
    "    Qk : NDArray\n",
    "        The process-noise covariance matrix at time k, shape (n,n).\n",
    "\n",
    "    Hk : NDArray\n",
    "        The measurement Jacobian evaluated at the current estimate,\n",
    "        used in the update. Shape (m,n).\n",
    "\n",
    "    Rk : NDArray\n",
    "        The measurement-noise covariance matrix at time k, shape (m,m).\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (x_upd, P_upd) : Tuple[NDArray, NDArray]\n",
    "        The updated state estimate and covariance:\n",
    "            - ``x_upd`` : updated state estimate, shape (n,1)\n",
    "            - ``P_upd`` : updated state covariance, shape (n,n)\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This implementation follows the standard **linearized EKF equations**:\n",
    "\n",
    "    **Predict step**\n",
    "    ----------------\n",
    "    State prediction:\n",
    "        ``x_pred = f(**f_params)``\n",
    "\n",
    "    Covariance prediction:\n",
    "        ``P_pred = Fk @ Pk @ Fk.T + Qk``\n",
    "\n",
    "    **Update step**\n",
    "    ---------------\n",
    "    Innovation:\n",
    "        ``innovation = yk - y_pred``\n",
    "        where ``y_pred = h(**h_params)``\n",
    "\n",
    "    Innovation covariance:\n",
    "        ``Sk = Hk @ P_pred @ Hk.T + Rk``\n",
    "\n",
    "    Kalman gain:\n",
    "        ``Kk = P_pred @ Hk.T @ Sk^{-1}``\n",
    "\n",
    "    State update:\n",
    "        ``x_upd = x_pred + Kk @ innovation``\n",
    "\n",
    "    Covariance update (Joseph form for numerical stability):\n",
    "        ``P_upd = (I - Kk @ Hk) @ P_pred @ (I - Kk @ Hk).T + Kk @ Rk @ Kk.T``\n",
    "\n",
    "    The covariance matrix is explicitly symmetrized at the end to counter\n",
    "    numerical drift:\n",
    "        ``P_upd = 0.5 * (P_upd + P_upd.T)``\n",
    "    \"\"\"\n",
    "\n",
    "    # === Extract covariance ===\n",
    "    _, Pk = xhat_P\n",
    "\n",
    "    # === Predict ===\n",
    "    x_pred = f(**f_params)\n",
    "    P_pred = Fk @ Pk @ Fk.T + Qk\n",
    "\n",
    "    # === Innovation ===\n",
    "    y_pred = h(**h_params)\n",
    "    innovation = yk - y_pred\n",
    "\n",
    "    # === Update ===\n",
    "    Sk = Hk @ P_pred @ Hk.T + Rk\n",
    "    ridge = 1e-9 * np.eye(Sk.shape[0])\n",
    "    try:\n",
    "        Sk_inv = np.linalg.inv(Sk + ridge)\n",
    "    except np.linalg.LinAlgError:\n",
    "        Sk_inv = np.linalg.pinv(Sk + ridge)\n",
    "\n",
    "    Kk = P_pred @ Hk.T @ Sk_inv\n",
    "    x_upd = x_pred + Kk @ innovation\n",
    "\n",
    "    I = np.eye(P_pred.shape[0])\n",
    "    P_upd = (I - Kk @ Hk) @ P_pred @ (I - Kk @ Hk).T + Kk @ Rk @ Kk.T\n",
    "    P_upd = 0.5 * (P_upd + P_upd.T)\n",
    "\n",
    "    return (x_upd, P_upd)\n",
    "\n",
    "\n",
    "def h(xhat_P: Tuple[NDArray, NDArray]) -> NDArray:\n",
    "    return xhat_P[0]  # extracts current state estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b20c2",
   "metadata": {},
   "source": [
    "## Example: 1D Constant Velocity Tracking\n",
    "::: note\n",
    "Finally, show an example of your algorithm in action.\n",
    ":::\n",
    "We track a target moving in **1D with (approximately) constant velocity**, where we only observe its **position**. We also include process and measurement noise using `pykal.data_change.corrupt`.\n",
    "\n",
    "We consider the 1D constant-velocity model with state\n",
    "\n",
    "$$\n",
    "x_k = \\begin{bmatrix} p_k \\\\ v_k \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where $p_k$ is position and $v_k$ is velocity at discrete time $k$.\n",
    "\n",
    "The discrete-time dynamics with sampling interval $\\Delta t$ are:\n",
    "\n",
    "$$\n",
    "x_{k+1} =\n",
    "\\begin{bmatrix}\n",
    "1 & \\Delta t \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "x_k + w_k,\n",
    "$$\n",
    "\n",
    "where $w_k \\sim \\mathcal{N}(0, Q)$ is process noise (acceleration noise).\n",
    "\n",
    "The measurement model observes **position only**:\n",
    "\n",
    "$$\n",
    "y_k =\n",
    "\\begin{bmatrix}\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "x_k + v_k,\n",
    "$$\n",
    "\n",
    "where $v_k \\sim \\mathcal{N}(0, R)$ is measurement noise. If we model unknown accelerations as white noise, a standard discrete-time covariance is:\n",
    "\n",
    "$$\n",
    "Q = \\sigma_a^2\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\Delta t^4}{4} & \\frac{\\Delta t^3}{2} \\\\\n",
    "\\frac{\\Delta t^3}{2} & \\Delta t^2\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "and the measurement covariance is:\n",
    "\n",
    "$$\n",
    "R = \\sigma_y^2.\n",
    "$$\n",
    "\n",
    "In this example we choose:\n",
    "\n",
    "- process noise covariance: $Q = \\begin{bmatrix} 10^{-4} & 0 \\\\ 0 & 10^{-4} \\end{bmatrix}$\n",
    "- measurement noise covariance: $R = \\begin{bmatrix} 10^{-3} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19659a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykal import DynamicalSystem\n",
    "import matplotlib.pyplot as plt  # for plotting\n",
    "\n",
    "\n",
    "def target_f(xk, Ak):\n",
    "    \"\"\"Noise-free state evolution.\"\"\"\n",
    "    xk_next = Ak @ xk\n",
    "    return xk_next\n",
    "\n",
    "\n",
    "def target_h(xk, Ck):\n",
    "    \"\"\"Noise-free measurement.\"\"\"\n",
    "    yk = Ck @ xk\n",
    "    return yk\n",
    "\n",
    "\n",
    "target = DynamicalSystem(f=target_f, h=target_h, state_name=\"pos_vel\")\n",
    "\n",
    "kf = DynamicalSystem(f=f, h=h, state_name=\"xest_P\")  # define the kf dynamical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b348dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pykal.data_change import corrupt\n",
    "\n",
    "# Define covariances\n",
    "Qk = np.array([[1e-4, 0], [0, 1e-4]])\n",
    "Rk = np.array([[1e-3]])\n",
    "Pk = np.array([[1e-3, 0], [0, 1e-3]])\n",
    "\n",
    "# Initial state (column vector)\n",
    "xk = np.array([[0.0], [1.0]])\n",
    "xk_kf = [xk, Pk]\n",
    "measurements = []\n",
    "kf_state_estimates = []\n",
    "\n",
    "dt = 0.1\n",
    "for tk in np.arange(0, 10, dt):\n",
    "\n",
    "    Ak = np.array([[1, dt], [0, 1]])\n",
    "    Ck = np.array([[1, 0]])\n",
    "\n",
    "    # Noise-free state evolution\n",
    "    xk = target.f(xk=xk, Ak=Ak)\n",
    "\n",
    "    # Apply process noise using pykal.data_change.corrupt\n",
    "    xk = corrupt.with_gaussian_noise(xk.flatten(), Q=Qk).reshape(-1, 1)\n",
    "\n",
    "    # Noise-free measurement\n",
    "    yk = target.h(xk=xk, Ck=Ck)\n",
    "\n",
    "    # Apply measurement noise using pykal.data_change.corrupt\n",
    "    yk = corrupt.with_gaussian_noise(yk.flatten(), Q=Rk).reshape(-1, 1)\n",
    "\n",
    "    xk_kf, yk_kf = kf.step(\n",
    "        return_state=True,\n",
    "        param_dict={\n",
    "            \"xhat_P\": xk_kf,\n",
    "            \"yk\": yk,\n",
    "            \"f\": target_f,\n",
    "            \"f_params\": {\"xk\": xk_kf[0], \"Ak\": Ak},\n",
    "            \"h\": target_h,\n",
    "            \"h_params\": {\"xk\": xk_kf[0], \"Ck\": Ck},\n",
    "            \"Fk\": Ak,  # linear system means Fk and Hk are just Ak and Ck\n",
    "            \"Hk\": Ck,\n",
    "            \"Qk\": Qk,\n",
    "            \"Rk\": Rk,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    measurements.append(yk)\n",
    "    kf_state_estimates.append(yk_kf)\n",
    "\n",
    "meas_df = pd.DataFrame(np.vstack(measurements), columns=[\"Position\"])\n",
    "meas_df.plot()\n",
    "\n",
    "kf_state_est_df = pd.DataFrame(\n",
    "    np.array(kf_state_estimates).squeeze(),\n",
    "    columns=[\"Estimated Position\", \"Estimated Velocity\"],\n",
    ")\n",
    "kf_state_est_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d501247",
   "metadata": {},
   "source": [
    "\n",
    "## Notes on Usage\n",
    "Add notes you think users of this algorithm should know.\n",
    "\n",
    "This section provides practical guidance on when and how to use the Kalman filter implementation.\n",
    "\n",
    "### When to Use This Algorithm\n",
    "\n",
    "The Kalman filter is appropriate when **all** of the following conditions hold:\n",
    "\n",
    "1. **Linear dynamics**: The system evolution and measurement models are linear (or have been linearized)\n",
    "2. **Gaussian noise**: Process noise and measurement noise are approximately Gaussian\n",
    "3. **Known covariances**: The noise covariance matrices $Q$ and $R$ can be estimated or characterized\n",
    "4. **Real-time requirements**: You need recursive, online state estimation with constant memory\n",
    "\n",
    "If your system is **nonlinear**, consider using the Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF) instead. If your noise is **non-Gaussian** (e.g., heavy-tailed, multimodal), consider particle filters or other robust estimators.\n",
    "\n",
    "### Common Applications\n",
    "\n",
    "The Kalman filter is widely used in:\n",
    "\n",
    "- **Navigation and tracking**: GPS/IMU fusion, target tracking, vehicle localization\n",
    "- **Robotics**: State estimation for mobile robots, quadrotors, manipulators\n",
    "- **Control systems**: Observer design for output feedback control\n",
    "- **Signal processing**: Noise reduction, sensor fusion, time series prediction\n",
    "- **Economics**: Estimating hidden states in econometric models\n",
    "\n",
    "### Jacobian Requirements\n",
    "\n",
    "For **linear systems**, the Jacobians are simply the system matrices:\n",
    "\n",
    "- State transition Jacobian: $F_k$ is the linearized dynamics matrix\n",
    "- Measurement Jacobian: $H_k$ is the linearized measurement matrix\n",
    "\n",
    "In this implementation:\n",
    "- `Fk` should be the Jacobian $\\frac{\\partial f}{\\partial x}$ evaluated at the current estimate\n",
    "- `Hk` should be the Jacobian $\\frac{\\partial h}{\\partial x}$ evaluated at the current estimate\n",
    "\n",
    "For **time-invariant linear systems** (constant matrices), these are the same at every time step. For **time-varying or nonlinear systems**, recompute the Jacobians at each step.\n",
    "\n",
    "### Implementation Details\n",
    "\n",
    "**State representation**: The algorithm state is a tuple `(xhat, P)` where:\n",
    "- `xhat`: state estimate as a column vector, shape `(n, 1)`\n",
    "- `P`: covariance matrix, shape `(n, n)`\n",
    "\n",
    "**Plant model functions**: Provide noise-free functions `f` and `h`:\n",
    "- `f(**f_params)`: returns the predicted state (no process noise)\n",
    "- `h(**h_params)`: returns the predicted measurement (no measurement noise)\n",
    "\n",
    "**Noise handling**: Apply noise corruption separately using `pykal.data_change.corrupt` during simulation, as shown in the example. This separates the deterministic model from stochastic effects.\n",
    "\n",
    "**Numerical stability**: This implementation uses:\n",
    "- Joseph form covariance update for numerical stability\n",
    "- Ridge regularization (`1e-9 * I`) to avoid singular matrices\n",
    "- Pseudo-inverse fallback if matrix inversion fails\n",
    "- Explicit symmetrization of covariance to counter numerical drift\n",
    "\n",
    "### Tuning Guidance\n",
    "\n",
    "The performance of the Kalman filter depends critically on the noise covariance matrices:\n",
    "\n",
    "- **Process noise $Q$**: Larger values \u2192 filter trusts model less, adapts faster to changes\n",
    "- **Measurement noise $R$**: Larger values \u2192 filter trusts measurements less, smoother estimates\n",
    "\n",
    "**Initial covariance $P_0$**: Set based on initial uncertainty. Large values indicate high initial uncertainty; the filter will converge as measurements arrive.\n",
    "\n",
    "For practical tuning, see [this guide on tuning Kalman filters](https://shepherdmoon.org/kalman_filter/tuning.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\u2190 Algorithms as Dynamical Systems](../../getting_started/theory_to_python/algorithms_as_dynamical_systems.rst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}