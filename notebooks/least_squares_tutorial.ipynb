{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6059d5",
   "metadata": {},
   "source": [
    "# Least Squares Tutorial\n",
    "\n",
    "This notebook walks through the theory and implementation of the **Least Squares** estimation problem, as introduced in the `pykal` documentation. It covers:\n",
    "\n",
    "1. Motivation from inverse problems\n",
    "2. Batch linear least squares\n",
    "3. Sequential (recursive) least squares\n",
    "4. Sensor calibration example\n",
    "5. Connections to Kalman Filtering\n",
    "\n",
    "For derivations and full context, refer to the Theory & Background section in the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a371a",
   "metadata": {},
   "source": [
    "## Motivation: Inverse Problems\n",
    "\n",
    "We are given a system where outputs `y` are related to some unknown input `x` via a (possibly nonlinear) function `f(x)`:\n",
    "\n",
    "$$ f(x) = y $$\n",
    "\n",
    "But often this equation has no solution because `y` is not in the image of `f`. So instead, we solve the least-squares problem:\n",
    "\n",
    "$$ x^* = \\arg\\min_x \\|f(x) - y\\|_2^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1738bec",
   "metadata": {},
   "source": [
    "## Batch Linear Least Squares\n",
    "\n",
    "Assume a linear model:\n",
    "\n",
    "$$ y = A x + \\varepsilon $$\n",
    "\n",
    "The solution is given by the normal equations:\n",
    "\n",
    "$$ x^* = (A^T A)^{-1} A^T y $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ad25d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17745666, 0.04810827])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate sensor calibration data\n",
    "np.random.seed(42)\n",
    "T = np.linspace(0, 100, 20)  # known temperatures\n",
    "true_params = np.array([0.1, 0.05])  # offset and sensitivity\n",
    "y = true_params[0] + true_params[1] * T + np.random.normal(0, 0.1, size=T.shape)\n",
    "\n",
    "# Design matrix A\n",
    "A = np.vstack([np.ones_like(T), T]).T\n",
    "# Batch least squares\n",
    "x_star = np.linalg.inv(A.T @ A) @ A.T @ y\n",
    "x_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.scatter(T, y, label='Noisy measurements')\n",
    "plt.plot(T, A @ x_star, label='Least-squares fit', color='red')\n",
    "plt.xlabel('Temperature (Â°C)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.title('Sensor Calibration via Batch Least Squares')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0995613a",
   "metadata": {},
   "source": [
    "## Sequential (Recursive) Least Squares\n",
    "\n",
    "Update the estimate with each new measurement using:\n",
    "\n",
    "$$\n",
    "K_k = P_{k-1} a_k (a_k^T P_{k-1} a_k + \\sigma^2)^{-1},\n",
    "\\quad\n",
    "x_k = x_{k-1} + K_k (y_k - a_k^T x_{k-1}),\n",
    "\\quad\n",
    "P_k = (I - K_k a_k^T) P_{k-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Least Squares (RLS) implementation\n",
    "x_rls = np.zeros(2)\n",
    "P = 100 * np.eye(2)\n",
    "sigma2 = 0.01\n",
    "\n",
    "for i in range(len(T)):\n",
    "    a_k = A[i].reshape(2, 1)\n",
    "    y_k = y[i]\n",
    "    K = P @ a_k / (a_k.T @ P @ a_k + sigma2)\n",
    "    x_rls = x_rls + (K.flatten() * (y_k - a_k.T @ x_rls))\n",
    "    P = (np.eye(2) - K @ a_k.T) @ P\n",
    "\n",
    "x_rls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10efb3a3",
   "metadata": {},
   "source": [
    "This estimate matches the batch solution closely, and is suitable for real-time updates.\n",
    "\n",
    "In practice, this approach is extended to dynamic systems via the **Kalman Filter**, which we treat in a separate notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
